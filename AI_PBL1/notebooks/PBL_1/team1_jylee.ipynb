{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import copy\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "\n",
    "\"\"\"\n",
    "Loosely inspired by http://abel.ee.ucla.edu/cvxopt/_downloads/mnist.py\n",
    "which is GPL licensed.\n",
    "\"\"\"\n",
    "\n",
    "def read(dataset = \"training\", path = \".\"):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels.idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels.idx1-ubyte')\n",
    "    else:\n",
    "        raise Exception(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "\n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_img(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, Y, model, default_param, param_grid, cv, save, filename):\n",
    "    \"\"\"\n",
    "    Train model using given parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    ------------------------\n",
    "    - X: training data images\n",
    "    - Y: training data labels\n",
    "    - model: estimator class (NOT object)\n",
    "    - default_param: default parameters you want to apply to model\n",
    "    - param_grid: used by GridSearchCV\n",
    "    - cv: k in K-Fold. cross-validation parameter\n",
    "    - save: whether you save trained model or not\n",
    "    - filename: path of file to save your model\n",
    "    \n",
    "    Returns:\n",
    "    ------------------------\n",
    "    - estimator: trained model.\n",
    "    \"\"\"\n",
    "    \n",
    "    clf = model(**default_param)\n",
    "    estimator = GridSearchCV(clf, param_grid, cv=cv, n_jobs=-1)\n",
    "    \n",
    "    estimator.fit(X, Y)\n",
    "    \n",
    "    if save:\n",
    "        joblib.dump(estimator, filename)\n",
    "        \n",
    "    return estimator\n",
    "\n",
    "def get_model(model, filename, param_grid=dict(), cv=6, X=None, Y=None, default_param=dict(), force_training=False, save=True):\n",
    "    \"\"\"\n",
    "    get model from existing file which has pre-trained model\n",
    "    or create new model.\n",
    "    \n",
    "    Arguments:\n",
    "    --------------------------\n",
    "    - model: class of estimator\n",
    "    - filename: name of file which contains pre-trained model.\n",
    "    - default_param: default parameters you want to apply to model\n",
    "    - param_grid: parameters you want to pass to GridSearchCV as parameters of 'param_grid'\n",
    "    - cv: cross-validation parameter\n",
    "    - X: training data images\n",
    "    - Y: training data labels\n",
    "    - forece_training: if you want this function to ONLY train not load from file, set True.\n",
    "    - save: if you want to save model after training, set this True.\n",
    "    \n",
    "    Returns:\n",
    "    --------------------------\n",
    "    - estimator: model trained.\n",
    "    \"\"\"\n",
    "    \n",
    "    path = pathlib.Path(filename)\n",
    "    estimator = None\n",
    "    \n",
    "    if force_training == True:\n",
    "        estimator = train_model(X, Y, model, default_param, param_grid, cv, save, filename)\n",
    "    else:\n",
    "        if path.exists(): # if file exists, just load that.\n",
    "            estimator = joblib.load(filename)\n",
    "        else:\n",
    "            estimator = train_model(X, Y, model, default_param, param_grid, cv, save, filename)\n",
    "            \n",
    "    return estimator\n",
    "\n",
    "def get_model_without_gridsearch(model, filename, default_param=dict(), X=None, Y=None, save=True):\n",
    "    \"\"\"\n",
    "    Another version of get model without GridSearchCV\n",
    "    \n",
    "    Arguments:\n",
    "    -----------------------------\n",
    "    model: class name of estimator\n",
    "    filename: name of file to store our model into.\n",
    "    default_param: default parameter you want to pass into model.\n",
    "    X: features of training dataset\n",
    "    Y: labels of training dataset\n",
    "    save: if you want to save model after training, set it to True. default: True\n",
    "    \n",
    "    Returns:\n",
    "    -----------------------------\n",
    "    estimator: model which is trained already.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pathlib.Path(filename).exists():\n",
    "        estimator = joblib.load(filename)\n",
    "    else:\n",
    "        estimator = model(**default_param)\n",
    "        estimator.fit(X, Y)\n",
    "        if save:\n",
    "            joblib.dump(estimator, filename)\n",
    "        \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_sampling(images, labels, n_samples=10000):\n",
    "    \"\"\"\n",
    "    Randomly and EQUALLY sampling dataset.\n",
    "    In this function, all digits have same weights.\n",
    "    For example, if you passed n_samples as 10000,\n",
    "    number 0 is to be 1000\n",
    "    number 1 is to be 1000\n",
    "    ...\n",
    "    number 9 is to be 1000\n",
    "    \n",
    "    Arguments:\n",
    "    ------------------------\n",
    "    images: image dataset to be sampled of size n_samples\n",
    "    labels: label dataset to be sampled.\n",
    "    n_samples: sample size.\n",
    "    \n",
    "    Returns:\n",
    "    -------------------------\n",
    "    result_images: image sampled into n_samples\n",
    "    result_labels: image sampled into n_samples\n",
    "    \"\"\"\n",
    "    \n",
    "    # placeholder for sampled dataset.\n",
    "    result_images = np.zeros((n_samples, 28, 28))\n",
    "    result_labels = np.zeros((n_samples,))\n",
    "    \n",
    "    # sampling\n",
    "    for i in range(10):\n",
    "        # to sample all digits equally.\n",
    "        temp_images = images[labels == i]\n",
    "        temp_labels = labels[labels == i]\n",
    "        \n",
    "        random_index = np.random.randint(0, temp_images.shape[0], size=1000)\n",
    "        \n",
    "        result_images[i * 1000 : (i + 1) * 1000] = temp_images[random_index]\n",
    "        result_labels[i * 1000 : (i + 1) * 1000] = temp_labels[random_index]\n",
    "        \n",
    "    return result_images, result_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset From Files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# read dataset fron file.\n",
    "\n",
    "tr = list(read(\"training\", \"data/\"))\n",
    "ts = list(read(\"testing\", 'data/'))\n",
    "\n",
    "images_train = np.array(list(zip(*tr))[1])\n",
    "labels_train = np.array(list(zip(*tr))[0])\n",
    "\n",
    "images_test = np.array(list(zip(*ts))[1])\n",
    "labels_test = np.array(list(zip(*ts))[0])\n",
    "\n",
    "print(images_train.shape)\n",
    "print(labels_train.shape)\n",
    "print(images_test.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Using Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding(images, n=1):\n",
    "    \"\"\"\n",
    "    zero-padding to image.\n",
    "    add additional edge which has value of 0\n",
    "    \n",
    "    Arguments:\n",
    "    ---------------------\n",
    "    - images: training dataset images. maybe (60000, 28, 28)\n",
    "    - n: how many padding do you want? in other word, how many edge do you want to insert?\n",
    "    \n",
    "    Returns:\n",
    "    ---------------------\n",
    "    - images_padded: padded images. (60000, 30, 30) or other shape.\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of training examples. 60000. if you use test data, 10000.\n",
    "    m = images.shape[0]\n",
    "    \n",
    "    # define larger size of window than size of images. maybe (60000, 30, 30), (60000, 32, 32)\n",
    "    images_padded = np.zeros((m, images.shape[1] + 2 * n, images.shape[2] + 2 * n))\n",
    "    \n",
    "    # insert image in the middle of this window.\n",
    "    images_padded[:, n : images_padded.shape[1] - n, n : images_padded.shape[2] - n] = images\n",
    "    \n",
    "    return images_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_gradient_slice(images_slice):\n",
    "    \"\"\"\n",
    "    find gradient(in korean, 기울기 또는 미분값) for part of images.\n",
    "    \n",
    "    Arguments:\n",
    "    ----------------------\n",
    "    - images_slice: small window extracted from images. (60000, 7, 7)\n",
    "    \n",
    "    Returns:\n",
    "    ----------------------\n",
    "    - grad: x-axis-oriented gradient (in korean, x 축 방향 기울기)\n",
    "    \"\"\"\n",
    "    \n",
    "    x_gradient_filter = np.array([\n",
    "        [-1,  0,  1],\n",
    "        [-1,  0,  1],\n",
    "        [-1,  0,  1],\n",
    "    ])\n",
    "    \n",
    "    # reshape for broadcasting.\n",
    "    x_gradient_filter = x_gradient_filter.reshape(1, 3, 3)\n",
    "    \n",
    "    # element-wise compute. compute gradient\n",
    "    temp = np.multiply(images_slice, x_gradient_filter)\n",
    "    grad = np.sum(temp, axis=(1, 2))\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_gradient(images):\n",
    "    \"\"\"\n",
    "    find gradient(in korean, 기울기 또는 미분값) for whole images.\n",
    "    \n",
    "    Arguments:\n",
    "    ----------------------\n",
    "    - images: images. (60000, 28, 28)\n",
    "    \n",
    "    Returns:\n",
    "    ----------------------\n",
    "    - grad: x-axis-oriented gradient (in korean, x 축 방향 기울기)\n",
    "    \"\"\"\n",
    "    \n",
    "    # some useful variables.\n",
    "    m = images.shape[0]\n",
    "    width = images.shape[1]\n",
    "    height = images.shape[2]\n",
    "    \n",
    "    # define placeholder to store gradients.\n",
    "    x_grads = np.zeros((m, width - 2, height - 2))\n",
    "    \n",
    "    # slice image into small size window, then compute gradient.\n",
    "    for w in range(1, width - 1):\n",
    "        for h in range(1, height - 1):\n",
    "            images_slice = images[:, w - 1 : w + 2, h - 1 : h + 2]\n",
    "            x_grads[:, w - 1, h - 1] = x_gradient_slice(images_slice)\n",
    "            \n",
    "    return x_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_gradient_slice(images_slice):\n",
    "    \"\"\"\n",
    "    find gradient(in korean, 기울기 또는 미분값) for part of images.\n",
    "    \n",
    "    Arguments:\n",
    "    ----------------------\n",
    "    - images_slice: small window extracted from images. (60000, 7, 7)\n",
    "    \n",
    "    Returns:\n",
    "    ----------------------\n",
    "    - grad: y-axis-oriented gradient (in korean, y 축 방향 기울기)\n",
    "    \"\"\"\n",
    "    \n",
    "    y_gradient_filter = np.array([\n",
    "        [-1, -1, -1],\n",
    "        [ 0,  0,  0],\n",
    "        [ 1,  1,  1],\n",
    "    ])\n",
    "    \n",
    "    # reshape for broadcasting.\n",
    "    y_gradient_filter = y_gradient_filter.reshape(1, 3, 3)\n",
    "    \n",
    "    # element-wise compute. compute gradient\n",
    "    temp = np.multiply(images_slice, y_gradient_filter)\n",
    "    grad = np.sum(temp, axis=(1, 2))\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_gradient(images):\n",
    "    \"\"\"\n",
    "    find gradient(in korean, 기울기 또는 미분값) for whole images.\n",
    "    \n",
    "    Arguments:\n",
    "    ----------------------\n",
    "    - images: images. (60000, 28, 28)\n",
    "    \n",
    "    Returns:\n",
    "    ----------------------\n",
    "    - grad: y-axis-oriented gradient (in korean, y 축 방향 기울기)\n",
    "    \"\"\"\n",
    "    \n",
    "    # some useful variables.\n",
    "    m = images.shape[0]\n",
    "    width = images.shape[1]\n",
    "    height = images.shape[2]\n",
    "    \n",
    "    # define placeholder to store gradients.\n",
    "    y_grads = np.zeros((m, width - 2, height - 2))\n",
    "    \n",
    "    # slice image into small size window, then compute gradient.\n",
    "    for w in range(1, width - 1):\n",
    "        for h in range(1, height - 1):\n",
    "            images_slice = images[:, w - 1 : w + 2, h - 1 : h + 2]\n",
    "            y_grads[:, w - 1, h - 1] = y_gradient_slice(images_slice)\n",
    "            \n",
    "    return y_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_grads(x_grads, y_grads, grid=7):\n",
    "    \"\"\"\n",
    "    After we get gradients, let's compute average of these gradient. I'will post pictures.\n",
    "    compute partial gradients.\n",
    "    \n",
    "    Arguments:\n",
    "    ---------------------\n",
    "    - x_grads: pre-computed gradients for x-axis (60000, 28, 28)\n",
    "    - y_grads: pre-computed gradients for y-axis (60000, 28, 28)\n",
    "    - grid: grid for dividing images. we will compute average of gradients for each grid. the averages become features.\n",
    "    \n",
    "    Returns:\n",
    "    ---------------------\n",
    "    - x_avg_grads: average of gradients x-axis (60000, 7, 7)\n",
    "    - y_avg_grads: average of gradients y-axis (60000, 7, 7)\n",
    "    \"\"\"\n",
    "    \n",
    "    assert(x_grads.shape == y_grads.shape)\n",
    "    \n",
    "    # some useful variables.\n",
    "    m = x_grads.shape[0]\n",
    "    width = x_grads.shape[1]\n",
    "    height = x_grads.shape[2]\n",
    "    \n",
    "    # I define these variables to slicing images conveniently.\n",
    "    w_step = width // grid  # w_step = 4\n",
    "    h_step = height // grid # h_step = 4\n",
    "    \n",
    "    # placeholder for storing average of gradients\n",
    "    x_avg_grads = np.zeros((m, width // w_step, height // h_step))\n",
    "    y_avg_grads = np.zeros((m, width // w_step, height // h_step))\n",
    "    \n",
    "    for w in range(0, width, w_step):\n",
    "        for h in range(0, height, h_step):\n",
    "            # slicing gradients into small part.\n",
    "            x_grads_slice = x_grads[:, w : w + w_step, h : h + h_step]\n",
    "            y_grads_slice = y_grads[:, w : w + w_step, h : h + h_step]\n",
    "            \n",
    "            assert(x_grads_slice.shape == y_grads_slice.shape == (m, width // grid, height // grid))\n",
    "            \n",
    "            # compute mean of gradients of part of image\n",
    "            x_avg_grads[:, w // w_step, h // h_step] = np.mean(x_grads_slice, axis=(1, 2))\n",
    "            y_avg_grads[:, w // w_step, h // h_step] = np.mean(y_grads_slice, axis=(1, 2))\n",
    "            \n",
    "    return x_avg_grads, y_avg_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_gradients_grid(images, grid=7, padding=1, normalize=True):\n",
    "    \"\"\"\n",
    "    Preprocessing method 1 which I tried.\n",
    "    \n",
    "    Arguments:\n",
    "    -------------------------\n",
    "    - images: training or test images (60000, 28, 28)\n",
    "    - grid: grid for dividing images. we will compute average of gradients for each grid. the averages become features.\n",
    "    - padding: how much padding image.\n",
    "    \n",
    "    Returns:\n",
    "    -------------------------\n",
    "    - features: pre-processed features (pixel of images). (60000, 98)\n",
    "    \"\"\"\n",
    "    \n",
    "    images = np.copy(images)\n",
    "    \n",
    "    m = images.shape[0]\n",
    "    \n",
    "    # normalize\n",
    "    if normalize:\n",
    "        images_norm = images / 255\n",
    "    else:\n",
    "        images_norm = images\n",
    "    \n",
    "    # thresholding\n",
    "    images_norm[images_norm >= 0.1] = 1\n",
    "    images_norm[images_norm < 0.1] = 0\n",
    "    \n",
    "    # zero padding\n",
    "    images_padded = zero_padding(images_norm, padding)\n",
    "    \n",
    "    # number of features = grid^2 * 2\n",
    "    features = np.zeros((m, (grid ** 2) * 2))\n",
    "\n",
    "    # compute x-axis gradient, y-axis gradient\n",
    "    x_grads = x_gradient(images_padded)\n",
    "    y_grads = y_gradient(images_padded)\n",
    "    \n",
    "    # compute average of gradient (grid 7x7)\n",
    "    x_avg_grads, y_avg_grads = get_average_grads(x_grads, y_grads, grid)\n",
    "    \n",
    "    assert(x_avg_grads.shape == y_avg_grads.shape == (m, grid, grid))\n",
    "    \n",
    "    # flatten\n",
    "    x_features = x_avg_grads.reshape(m, -1)\n",
    "    y_features = y_avg_grads.reshape(m, -1)\n",
    "    \n",
    "    features[:, : grid ** 2] = x_features\n",
    "    features[:, grid ** 2 :] = y_features\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's start! First, we compute gradient features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_1_X_train = average_gradients_grid(images_train)\n",
    "preprocessed_1_X_test = average_gradients_grid(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 98)\n",
      "(10000, 98)\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_1_X_train.shape)\n",
    "print(preprocessed_1_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV with un-preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = dataset_sampling(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(10000, -1)\n",
    "X_test = images_test.reshape(10000, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train.reshape(10000, 28, 28)[3])\n",
    "plt.show()\n",
    "print(Y_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator SVC from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator SVC from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator GridSearchCV from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': [0.001, 0.01, 0.1]\n",
    "    },\n",
    "    {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'kernel': ['poly'],\n",
    "        'gamma': [0.001, 0.01, 0.1],\n",
    "        'degree': [2, 3]\n",
    "    }\n",
    "]\n",
    "\n",
    "clf_svc = get_model(SVC, 'data/svm.model_data', param_grid=param_grid, cv=5, X=X_train, Y=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=clf_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9619\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy:', svc.score(X_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# parameters for grid search.\n",
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l2', 'l1'],\n",
    "        'alpha': [1e-7, 1e-5, 1e-3, 1e-1],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {\n",
    "        'penalty': [None],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    }\n",
    "]\n",
    "\n",
    "# load or train models.\n",
    "clf_percp_1_1 = get_model(Perceptron, 'data/perceptron_1.model_data', param_grid, cv=6, X=preprocessed_1_X_train, Y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-05, 'class_weight': None, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "# get best parameters.\n",
    "param_percp_1_1 = clf_percp_1_1.best_params_\n",
    "print(param_percp_1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.8462666666666666\n",
      "Accuracy on test set:\n",
      "0.8459\n"
     ]
    }
   ],
   "source": [
    "# get best perceptron model which was tested on grid search. This contain best parameters.\n",
    "percp_1_1 = clf_percp_1_1.best_estimator_\n",
    "\n",
    "# get best accuracy on training set\n",
    "print('Accuracy on training set:')\n",
    "print(clf_percp_1_1.best_score_)\n",
    "\n",
    "# predict accuracy on test set using best perceptron.\n",
    "print('Accuracy on test set:')\n",
    "print(percp_1_1.score(preprocessed_1_X_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters passed to grid search.\n",
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1000], # 1000 means no regularization\n",
    "        'class_weight': [None, 'balanced'],\n",
    "    }\n",
    "]\n",
    "\n",
    "# load or train model.\n",
    "clf_logs_1_1 = get_model(LogisticRegression, 'data/logistic_1.model_data', param_grid, 6, X=preprocessed_1_X_train, Y=labels_train, default_param=dict(solver='lbfgs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'class_weight': 'balanced', 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "# get and print best hyper parameters\n",
    "param_logs_1_1 = clf_logs_1_1.best_params_\n",
    "print(param_logs_1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best logistic regression we found on grid search. This contain best parameters.\n",
    "logs_1_1 = clf_logs_1_1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.89755\n",
      "Accuracy on test set:\n",
      "0.9074\n"
     ]
    }
   ],
   "source": [
    "# get best accuracy on training set\n",
    "print('Accuracy on training set:')\n",
    "print(clf_logs_1_1.best_score_)\n",
    "\n",
    "# compute accuracy on test set using best logistic regression\n",
    "print('Accuracy on test set:')\n",
    "print(logs_1_1.score(preprocessed_1_X_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "X_sample_train, Y_sample_train = dataset_sampling(images_train, labels_train)\n",
    "\n",
    "print(X_sample_train.shape)\n",
    "print(Y_sample_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 98)\n",
      "(10000, 98)\n"
     ]
    }
   ],
   "source": [
    "X_svc_grads_train = average_gradients_grid(X_sample_train)\n",
    "X_svc_grads_test = average_gradients_grid(images_test)\n",
    "\n",
    "print(X_svc_grads_train.shape)\n",
    "print(X_svc_grads_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'kernel': ['sigmoid', 'rbf'],\n",
    "        'gamma': ['auto', 'scale', 0.001, 0.01, 0.1]\n",
    "    },\n",
    "    {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'kernel': ['poly'],\n",
    "        'gamma': ['auto', 'scale', 0.001, 0.01, 0.1],\n",
    "        'degree': [3, 4, 5]\n",
    "    }\n",
    "]\n",
    "\n",
    "clf_svc_1_1 = get_model(SVC, 'data/svm_1.model_data', param_grid=param_grid, cv=5, X=X_svc_grads_train, Y=Y_sample_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "params_svm_1_1 = clf_svc_1_1.best_params_\n",
    "print(params_svm_1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best logistic regression we found on grid search. This contain best parameters.\n",
    "svm_1_1 = clf_svc_1_1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.9692\n",
      "Accuracy on test set:\n",
      "0.9603\n"
     ]
    }
   ],
   "source": [
    "# get best accuracy on training set\n",
    "print('Accuracy on training set:')\n",
    "print(svm_1_1.score(X_svc_grads_train, Y_sample_train))\n",
    "\n",
    "# compute accuracy on test set using best logistic regression\n",
    "print('Accuracy on test set:')\n",
    "print(svm_1_1.score(X_svc_grads_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'C': [100, 300, 1000, 3000, 10000],\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': [0.1, 0.3, 1.0, 3.0, 10]\n",
    "    }\n",
    "]\n",
    "\n",
    "clf_svm_1_2 = get_model(SVC, 'data/svm_1_2.model_data', param_grid=param_grid, cv=5, X=X_svc_grads_train, Y=Y_sample_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_svm_1_2 = clf_svm_1_2.best_params_\n",
    "print(param_svm_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best logistic regression we found on grid search. This contain best parameters.\n",
    "svm_1_2 = clf_svm_1_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.9595\n",
      "Accuracy on test set:\n",
      "0.9603\n"
     ]
    }
   ],
   "source": [
    "# get best accuracy on training set\n",
    "print('Accuracy on training set:')\n",
    "print(clf_svm_1_2.best_score_)\n",
    "\n",
    "# compute accuracy on test set using best logistic regression\n",
    "print('Accuracy on test set:')\n",
    "print(svm_1_2.score(X_svc_grads_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting More Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 98)\n",
      "(10000, 98)\n"
     ]
    }
   ],
   "source": [
    "X_grid_train = average_gradients_grid(images_train)\n",
    "X_grid_test = average_gradients_grid(images_test)\n",
    "\n",
    "print(X_grid_train.shape)\n",
    "print(X_grid_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pathlib.Path('data/svm_1_3.model_data').exists():\n",
    "#     svc_1_3 = joblib.load('data/svm_1_3.model_data')\n",
    "# else:\n",
    "#     svc_1_3 = SVC(**params)\n",
    "#     svc_1_3.fit(X_grid_train, labels_train)\n",
    "#     joblib.dump(svc_1_3, 'data/svm_1_3.model_data')\n",
    "\n",
    "param_svm_1_3 = copy.deepcopy(param_svm_1_2)\n",
    "\n",
    "svm_1_3 = get_model_without_gridsearch(SVC, 'data/svm_1_3.model_data', default_param=param_svm_1_3, X=X_grid_train, Y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.0\n",
      "Accuracy on test set: 0.9738\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training set:', svm_1_3.score(X_grid_train, labels_train))\n",
    "print('Accuracy on test set:', svm_1_3.score(X_grid_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pathlib.Path('data/svm_1_4.model_data').exists():\n",
    "#     svc_1_4 = joblib.load('data/svm_1_4.model_data')\n",
    "# else:\n",
    "#     svc_1_4 = SVC(**params)\n",
    "#     svc_1_4.C = 10\n",
    "#     svc_1_4.fit(X_grid_train, labels_train)\n",
    "#     joblib.dump(svc_1_4, 'data/svm_1_4.model_data')\n",
    "\n",
    "param_svm_1_4 = copy.deepcopy(param_svm_1_3)\n",
    "param_svm_1_4['C'] = 10\n",
    "\n",
    "svm_1_4 = get_model_without_gridsearch(SVC, 'data/svm_1_4.model_data', default_param=param_svm_1_4, X=X_grid_train, Y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.9996\n",
      "Accuracy on test set: 0.9746\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training set:', svm_1_4.score(X_grid_train, labels_train))\n",
    "print('Accuracy on test set:', svm_1_4.score(X_grid_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pathlib.Path('data/svm_1_5.model_data').exists():\n",
    "#     svc_1_5 = joblib.load('data/svm_1_5.model_data')\n",
    "# else:\n",
    "#     svc_1_5 = SVC(**params)\n",
    "#     svc_1_5.C = 0.1\n",
    "#     svc_1_5.fit(X_grid_train, labels_train)\n",
    "#     joblib.dump(svc_1_5, 'data/svm_1_5.model_data')\n",
    "\n",
    "param_svm_1_5 = copy.deepcopy(param_svm_1_4)\n",
    "param_svm_1_5['C'] = 0.3\n",
    "\n",
    "svm_1_5 = get_model_without_gridsearch(SVC, 'data/svm_1_5.model_data', default_param=param_svm_1_5, X=X_grid_train, Y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.9784666666666667\n",
      "Accuracy on test set: 0.9687\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training set:', svm_1_5.score(X_grid_train, labels_train))\n",
    "print('Accuracy on test set:', svm_1_5.score(X_grid_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.85, 0.87, 0.90, 0.93, 0.95],\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [0.1]\n",
    "}\n",
    "\n",
    "clf_svm_1_6 = get_model(SVC, 'data/svm_1_6.model_data', param_grid=param_grid, cv=6, X=X_grid_train, Y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.95, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_svm_1_6 = clf_svm_1_6.best_params_\n",
    "print(param_svm_1_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_1_6 = clf_svm_1_6.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training dataset: 0.9737833333333333\n",
      "Accuracy on test dataset: 0.9742\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training dataset: {}'.format(clf_svm_1_6.best_score_))\n",
    "print('Accuracy on test dataset: {}'.format(svm_1_6.score(X_grid_test, labels_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [3, 4, 5],\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [0.1]\n",
    "}\n",
    "\n",
    "clf_svm_1_7 = get_model(SVC, 'data/svm_1_7.model_data', param_grid=param_grid, cv=6, X=X_grid_train, Y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_svm_1_7 = clf_svm_1_7.best_params_\n",
    "print(param_svm_1_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_1_7 = clf_svm_1_7.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training dataset: 0.9760833333333333\n",
      "Accuracy on test dataset: 0.9747\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training dataset: {}'.format(clf_svm_1_7.best_score_))\n",
    "print('Accuracy on test dataset: {}'.format(svm_1_7.score(X_grid_test, labels_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_svm_1_8 = copy.deepcopy(param_svm_1_7)\n",
    "param_svm_1_8['C'] = 7\n",
    "\n",
    "svm_1_8 = get_model_without_gridsearch(SVC, 'data/svm_1_8.model_data', default_param=param_svm_1_8, X=X_grid_train, Y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.99935\n",
      "Accuracy on test set: 0.9741\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training set: {}'.format(svm_1_8.score(X_grid_train, labels_train)))\n",
    "print('Accuracy on test set: {}'.format(svm_1_8.score(X_grid_test, labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_svm_1_9 = copy.deepcopy(param_svm_1_8)\n",
    "param_svm_1_9['C'] = 6\n",
    "svm_1_9 = get_model_without_gridsearch(SVC, 'data/svm_1_9.model_data', default_param=param_svm_1_9, X=X_grid_train, Y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.9991666666666666\n",
      "Accuracy on test set: 0.9744\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training set: {}'.format(svm_1_9.score(X_grid_train, labels_train)))\n",
    "print('Accuracy on test set: {}'.format(svm_1_9.score(X_grid_test, labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_svm_1_10 = copy.deepcopy(param_svm_1_9)\n",
    "param_svm_1_10['C'] = 5.25\n",
    "\n",
    "svm_1_10 = get_model_without_gridsearch(SVC, 'data/svm_1_10.model_data', default_param=param_svm_1_10, X=X_grid_train, Y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.999\n",
      "Accuracy on test set: 0.9746\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training set: {}'.format(svm_1_10.score(X_grid_train, labels_train)))\n",
    "print('Accuracy on test set: {}'.format(svm_1_10.score(X_grid_test, labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_svm_1_11 = copy.deepcopy(param_svm_1_10)\n",
    "param_svm_1_11['C'] = 5.025\n",
    "svm_1_11 = get_model_without_gridsearch(SVC, 'data/svm_1_11.model_data', default_param=param_svm_1_11, X=X_grid_train, Y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.9989166666666667\n",
      "Accuracy on test set: 0.9747\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training set: {}'.format(svm_1_11.score(X_grid_train, labels_train)))\n",
    "print('Accuracy on test set: {}'.format(svm_1_11.score(X_grid_test, labels_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: Just Features Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_reduction(images):\n",
    "    \"\"\"\n",
    "    Reduce features.\n",
    "    \n",
    "    Operation: For example, look at one pixel in an image.\n",
    "               If this pixel is one? then, look at neighbors of this pixel. if there are many pixel that has value of 1, then mark this pixel's position as 1.\n",
    "               If this pixel is zero, then mark this pixel positio as 0\n",
    "    \n",
    "    Arguments:\n",
    "    ---------------------\n",
    "    - images: training or test image dataset (m, image_size, image_size)\n",
    "    \n",
    "    Returns:\n",
    "    ---------------------\n",
    "    - reduced: result images after reducing features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # some useful variable.\n",
    "    m = images.shape[0]\n",
    "    width = images.shape[1]\n",
    "    height = images.shape[2]\n",
    "    \n",
    "    # you should mark in this variable.\n",
    "    reduced = np.zeros((m, width - 2, height - 2))\n",
    "    \n",
    "    for i in range(m):\n",
    "        for w in range(1, width - 1):\n",
    "            for h in range(1, height - 1):\n",
    "                if images[i, w, h] == 1:\n",
    "                    if np.sum(images[i, w - 1 : w + 2, h - 1 : h + 2]) > 3:\n",
    "                        reduced[i, w - 1, h - 1] = 1\n",
    "                        \n",
    "    return reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_supression(images):\n",
    "    \"\"\"\n",
    "    In fact, the operation is same as feature_reduction.\n",
    "    The difference is feature_reduction function don't care about pixel on out-most edge.\n",
    "    But, this function does care about pixel on out-most edge.\n",
    "    And, this function use the operation strictly. It make the hand-written-digit more thinner\n",
    "    \n",
    "    So, the roll of this function is make the digits image thin.\n",
    "    \n",
    "    If you conduct the operation on out-most edge, size of image should not be reduced.\n",
    "    \n",
    "    Arguments:\n",
    "    -------------------------\n",
    "    - images: training or test image dataset. (m, image_size, image_size)\n",
    "    \n",
    "    Returns:\n",
    "    -------------------------\n",
    "    - features: image after suppression\n",
    "    \"\"\"\n",
    "    m = images.shape[0]\n",
    "    width = images.shape[1]\n",
    "    height = images.shape[2]\n",
    "    \n",
    "    features = np.zeros((m, width, height))\n",
    "    \n",
    "    for i in range(m):\n",
    "        for w in range(1, width - 1):\n",
    "            if images[i, w, 0] == 1:\n",
    "                count = 0\n",
    "                if images[i, w - 1, 0] == 1:\n",
    "                    count += 1\n",
    "                if images[i, w + 1, 0] == 1:\n",
    "                    count += 1\n",
    "                if images[i, w, 1] == 1:\n",
    "                    count += 1\n",
    "                \n",
    "                if count >= 2:\n",
    "                    features[i, w, 0] = 1\n",
    "        \n",
    "        for h in range(1, height - 1):\n",
    "            if images[i, 0, h] == 1:\n",
    "                count = 0\n",
    "                if images[i, 0, h - 1] == 1:\n",
    "                    count += 1\n",
    "                if images[i, 0, h + 1] == 1:\n",
    "                    count += 1\n",
    "                if images[i, 0, h] == 1:\n",
    "                    count += 1\n",
    "                \n",
    "                if count >= 2:\n",
    "                    features[i, 0, h] = 1\n",
    "                    \n",
    "        for w in range(1, width - 1):\n",
    "            for h in range(1, height - 1):\n",
    "                if images[i, w, h] == 1:\n",
    "                    count = 0\n",
    "                    if images[i, w - 1, h] == 1:\n",
    "                        count += 1\n",
    "                    if images[i, w + 1, h] == 1:\n",
    "                        count += 1\n",
    "                    if images[i, w, h - 1] == 1:\n",
    "                        count += 1\n",
    "                    if images[i, w, h + 1] == 1:\n",
    "                        count += 1\n",
    "                        \n",
    "                    if count >= 3:\n",
    "                        features[i, w, h] = 1\n",
    "                        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_feature_reduction(images_train, images_test):\n",
    "    \"\"\"\n",
    "    Preprocessing method 2 I tryied\n",
    "    I mixed feature reduction and suppression.\n",
    "    \n",
    "    Arguments\n",
    "    ----------------------------\n",
    "    images_train: images in training dataset\n",
    "    images_test: images in test dataset\n",
    "    \n",
    "    Returns\n",
    "    ---------------------------\n",
    "    suppressed2_train: result of some feature reductions and suppressions on training dataset\n",
    "    suppressed2_test: result of some feature reductions and suppressions on test dataset\n",
    "    cache: middle results in the middle of redunction and suppression.\n",
    "    \"\"\"\n",
    "    \n",
    "    cache = dict()\n",
    "    \n",
    "    images_train[images_train >= 0.1] = 1\n",
    "    images_train[images_train < 0.1] = 0\n",
    "    \n",
    "    images_test[images_test >= 0.1] = 1\n",
    "    images_test[images_test < 0.1] = 0\n",
    "    \n",
    "    reduced1 = feature_reduction(images_train)\n",
    "\n",
    "    reduced2 = feature_reduction(reduced1)\n",
    "    suppressed1_train = feature_supression(reduced2)\n",
    "\n",
    "    reduced3 = feature_reduction(suppressed1_train)\n",
    "    suppressed2_train = feature_supression(reduced3)\n",
    "\n",
    "\n",
    "    reduced1_test = feature_reduction(images_test)\n",
    "\n",
    "    reduced2_test = feature_reduction(reduced1_test)\n",
    "    suppressed1_test = feature_supression(reduced2_test)\n",
    "\n",
    "    reduced3_test = feature_reduction(suppressed1_test)\n",
    "    suppressed2_test = feature_supression(reduced3_test)\n",
    "    \n",
    "    cache['reduced1'] = reduced1\n",
    "    cache['reduced2'] = reduced2\n",
    "    cache['reduced3'] = reduced3\n",
    "    cache['suppressed1_train'] = suppressed1_train\n",
    "    cache['suppressed2_train'] = suppressed2_train\n",
    "    cache['suppressed1_test'] = suppressed1_test\n",
    "    cache['suppressed2_test'] = suppressed2_test\n",
    "    \n",
    "    return suppressed2_train, suppressed2_test, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_images_train = images_train / 255\n",
    "norm_images_test = images_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressed_train, suppressed_test, cache = preprocessing_feature_reduction(norm_images_train, norm_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original images: (60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Original images: {}'.format(images_train.shape))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(1 - norm_images_train[0], cmap='gray')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(1 - norm_images_train[1], cmap='gray')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(1 - norm_images_train[2], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image after feature reduction: (60000, 22, 22)\n",
      "Stage 1: (60000, 26, 26)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x864 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2: (60000, 24, 24)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x864 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 3: (60000, 22, 22)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x864 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Image after feature reduction: {}'.format(suppressed_train.shape))\n",
    "\n",
    "\n",
    "print('Stage 1: {}'.format(cache['reduced1'].shape))\n",
    "plt.figure(figsize=(18, 12))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(1 - cache['reduced1'][0], cmap='gray')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(1 - cache['reduced1'][1], cmap='gray')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(1 - cache['reduced1'][2], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print('Stage 2: {}'.format(cache['suppressed1_train'].shape))\n",
    "plt.figure(figsize=(18, 12))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(1 - cache['suppressed1_train'][0], cmap='gray')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(1 - cache['suppressed1_train'][1], cmap='gray')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(1 - cache['suppressed1_train'][2], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print('Stage 3: {}'.format(suppressed_train.shape))\n",
    "plt.figure(figsize=(18, 12))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(1 - suppressed_train[0], cmap='gray')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(1 - suppressed_train[1], cmap='gray')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(1 - suppressed_train[2], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the features.\n",
    "flatten_train = suppressed_train.reshape(60000, -1)\n",
    "flatten_test = suppressed_test.reshape(10000, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator Perceptron from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator Perceptron from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator GridSearchCV from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# paramters for grid search.\n",
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l2', 'l1'],\n",
    "        'alpha': [1e-7, 1e-5, 1e-3, 1e-1],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {\n",
    "        'penalty': [None],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    }\n",
    "]\n",
    "\n",
    "clf_percp_2_1 = get_model(Perceptron, 'data/perceptron_2.model_data', param_grid, 6, X=flatten_train, Y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None, 'penalty': None}\n"
     ]
    }
   ],
   "source": [
    "# get best parameters of best perceptron model.\n",
    "param_percp_2_1 = clf_percp_2_1.best_params_\n",
    "print(param_percp_2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best perceptron which has the highest accuracy during cross validation.\n",
    "percp_2_1 = clf_percp_2_1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.8177\n",
      "Accuracy on test set:\n",
      "0.821\n"
     ]
    }
   ],
   "source": [
    "# get the highest accuracy on training set.\n",
    "print('Accuracy on training set:')\n",
    "print(clf_percp_2_1.best_score_)\n",
    "\n",
    "# compute accuracy on test dataset using best perceptron.\n",
    "print('Accuracy on test set:')\n",
    "print(percp_2_1.score(flatten_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator GridSearchCV from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# parameters for grid search.\n",
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1000],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "    }\n",
    "]\n",
    "\n",
    "clf_logs_2_1 = get_model(LogisticRegression, 'data/logistic_2.model_data', param_grid, 6, X=flatten_train, Y=labels_train, default_param=dict(solver='lbfgs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# get best parameters of best logistic model.\n",
    "print(clf_logs_2_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best logistic regression which computed the highest accuracy on training dataset.\n",
    "logs_2_1 = clf_logs_2_1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.8734\n",
      "Accuracy on test set:\n",
      "0.881\n"
     ]
    }
   ],
   "source": [
    "# get best accuracy on training set.\n",
    "print('Accuracy on training set:')\n",
    "print(clf_logs_2_1.best_score_)\n",
    "\n",
    "# compute an accuracy on test set using best logistic regression.\n",
    "print('Accuracy on test set:')\n",
    "print(logs_2_1.score(flatten_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "X_sample_train, Y_sample_train = dataset_sampling(norm_images_train, labels_train)\n",
    "\n",
    "print(X_sample_train.shape)\n",
    "print(Y_sample_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 22, 22)\n",
      "(10000, 22, 22)\n"
     ]
    }
   ],
   "source": [
    "X_svc_suppressed_train, X_svc_suppressed_test, cache = preprocessing_feature_reduction(X_sample_train, norm_images_test)\n",
    "\n",
    "print(X_svc_suppressed_train.shape)\n",
    "print(X_svc_suppressed_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'kernel': ['sigmoid', 'rbf'],\n",
    "        'gamma': ['auto', 'scale', 0.001, 0.01, 0.1]\n",
    "    },\n",
    "    {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'kernel': ['poly'],\n",
    "        'gamma': ['auto', 'scale', 0.001, 0.01, 0.1],\n",
    "        'degree': [3, 4, 5]\n",
    "    }\n",
    "]\n",
    "\n",
    "clf_svm_2_1 = get_model(SVC, 'data/svm_2.model_data', param_grid=param_grid, cv=5, X=X_svc_suppressed_train.reshape(10000, -1), Y=Y_sample_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_svm_2_1 = clf_svm_2_1.best_params_\n",
    "print(param_svm_2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best logistic regression which computed the highest accuracy on training dataset.\n",
    "svm_2_1 = clf_svm_2_1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.9355\n",
      "Accuracy on test set:\n",
      "0.9337\n"
     ]
    }
   ],
   "source": [
    "# get best accuracy on training set.\n",
    "print('Accuracy on training set:')\n",
    "print(clf_svm_2_1.best_score_)\n",
    "\n",
    "# compute an accuracy on test set using best logistic regression.\n",
    "print('Accuracy on test set:')\n",
    "print(svm_2_1.score(X_svc_suppressed_test.reshape(10000, -1), labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3: Fusing Method 1 and Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 24, 24)\n",
      "(10000, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "print(cache['suppressed1_train'].shape)\n",
    "print(cache['suppressed1_test'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_train = average_gradients_grid(cache['suppressed1_train'], grid=7, padding=3, normalize=False)\n",
    "fused_test = average_gradients_grid(cache['suppressed1_test'], grid=7, padding=3, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 98)\n",
      "(10000, 98)\n"
     ]
    }
   ],
   "source": [
    "print(fused_train.shape)\n",
    "print(fused_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator Perceptron from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator Perceptron from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator GridSearchCV from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# parameters for grid search.\n",
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l2', 'l1'],\n",
    "        'alpha': [1e-7, 1e-5, 1e-3, 1e-1],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {\n",
    "        'penalty': [None],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    }\n",
    "]\n",
    "\n",
    "clf_percp_3_1 = get_model(Perceptron, 'data/perceptron_3.model_data', param_grid, 6, X=fused_train, Y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-07, 'class_weight': None, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# get best parameters.\n",
    "params = clf_percp_3_1.best_params_\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.83155\n",
      "Accuracy on test set:\n",
      "0.828\n"
     ]
    }
   ],
   "source": [
    "# get best perceptron which produced best accuracy on training/valid set.\n",
    "estimator = clf_percp_3_1.best_estimator_\n",
    "\n",
    "# get best accuracy on training set\n",
    "print('Accuracy on training set:')\n",
    "print(clf_percp_3_1.best_score_)\n",
    "\n",
    "# compute accuracy on test set using best perceptron.\n",
    "print('Accuracy on test set:')\n",
    "print(estimator.score(fused_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "D:\\Users\\jylee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator GridSearchCV from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# parameters for grid search.\n",
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1000],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "    }\n",
    "]\n",
    "\n",
    "clf_logs_3_1 = get_model(LogisticRegression, 'data/logistic_3.model_data', param_grid, 6, X=fused_train, Y=labels_train, default_param=dict(solver='lbfgs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'class_weight': None, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(clf_logs_3_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.88615\n",
      "Accuracy on test set:\n",
      "0.8958\n"
     ]
    }
   ],
   "source": [
    "estimator = clf_logs_3_1.best_estimator_\n",
    "\n",
    "print('Accuracy on training set:')\n",
    "print(clf_logs_3_1.best_score_)\n",
    "\n",
    "print('Accuracy on test set:')\n",
    "print(estimator.score(fused_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 4: Polynomial Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hog(images_train, images_test):\n",
    "    m_tr = images_train.shape[0]\n",
    "    m_ts = images_test.shape[0]\n",
    "    \n",
    "    # compute HoG (Historgram of Gradients)\n",
    "    hog_train = np.zeros((m_tr, 81))\n",
    "    hog_test = np.zeros((m_ts, 81))\n",
    "    \n",
    "    for i in range(m_tr):\n",
    "        hog_train[i] = hog(images_train[i], block_norm='L2-Hys')\n",
    "    for i in range(m_ts):\n",
    "        hog_test[i] = hog(images_test[i], block_norm='L2-Hys')\n",
    "        \n",
    "    return hog_train, hog_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_model(grads, hogs, poly_degree):\n",
    "    \"\"\"\n",
    "    This function reads inputs (grads, hogs) and then append into one vector.\n",
    "    And, most importantly, make the features (grads + hogs vector) polynomial or exponential\n",
    "    This has an effect that makes algorithm be applied to non-linear-separatable dataset.\n",
    "    \n",
    "    Arguments\n",
    "    ---------------------------------\n",
    "    grads: features containing gradients of images\n",
    "    hogs: features containing histogram of gradients\n",
    "    \n",
    "    Returns\n",
    "    ---------------------------------\n",
    "    f_train: preprocessed features of training dataset this function generate\n",
    "    f_test: preprocessed features of test dataset this function generate\n",
    "    \"\"\"\n",
    "    \n",
    "    # get number of training set (60000), number of test set (10000)\n",
    "    m_train = grads[0].shape[0] # 60000\n",
    "    m_test = grads[1].shape[0]  # 10000\n",
    "    \n",
    "    # placeholder for new features.\n",
    "    f_train = np.zeros((m_train, (98 + 81) * poly_degree))\n",
    "    f_test = np.zeros((m_test, (98 + 81) * poly_degree)) \n",
    "    \n",
    "    grads_train, grads_test = grads[0], grads[1]\n",
    "    hogs_train, hogs_test = hogs[0], hogs[1]\n",
    "    \n",
    "    for i in range(poly_degree):\n",
    "        f_train[:, (98 + 81) * i : (98 + 81) * i + 98] = grads_train ** (i + 1)\n",
    "        f_train[:, (98 + 81) * i + 98 : (98 + 81) * (i + 1)] = hogs_train ** (i + 1)\n",
    "        f_test[:, (98 + 81) * i : (98 + 81) * i + 98] = grads_test ** (i + 1)\n",
    "        f_test[:, (98 + 81) * i + 98 : (98 + 81) * (i + 1)] = hogs_test ** (i + 1)\n",
    "        \n",
    "    return f_train, f_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_poly_features(images_train, images_test, poly_degree=3):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    -------------------------\n",
    "    images_train: images in training datase shaped of (60000, 28, 28)\n",
    "    images_test: images in test dataset shaped of (10000, 28, 28)\n",
    "    poly_degree: how many do you product exponentialy?\n",
    "    \n",
    "    Returns\n",
    "    -------------------------\n",
    "    f_train: new features preprocessed\n",
    "    f_test: new features of test images.\n",
    "    \"\"\"\n",
    "    \n",
    "    m_train = images_train.shape[0]\n",
    "    m_test = images_test.shape[0]\n",
    "    \n",
    "    # compute average of gradients\n",
    "    avg_grads_train = average_gradients_grid(images_train)\n",
    "    avg_grads_test = average_gradients_grid(images_test)\n",
    "    \n",
    "    hog_train, hog_test = apply_hog(images_train, images_test)\n",
    "        \n",
    "    f_train, f_test = poly_model((avg_grads_train, avg_grads_test), (hog_train, hog_test), poly_degree)\n",
    "    \n",
    "    return f_train, f_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_train, poly_test = make_poly_features(images_train, images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 537)\n",
      "(10000, 537)\n"
     ]
    }
   ],
   "source": [
    "print(poly_train.shape)\n",
    "print(poly_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l2', 'l1'],\n",
    "        'alpha': [1e-7, 1e-5, 1e-3, 1e-1],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {\n",
    "        'penalty': [None],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    }\n",
    "]\n",
    "\n",
    "clf_percp_4_1 = get_model(Perceptron, 'data/perceptron_4.model_data', param_grid=param_grid, cv=6, X=poly_train, Y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-05, 'class_weight': 'balanced', 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "params = clf_percp_4_1.best_params_\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.9444666666666667\n",
      "Accuracy on test set:\n",
      "0.9567\n"
     ]
    }
   ],
   "source": [
    "estimator = clf_percp_4_1.best_estimator_\n",
    "\n",
    "print('Accuracy on training set:')\n",
    "print(clf_percp_4_1.best_score_)\n",
    "\n",
    "print('Accuracy on test set:')\n",
    "print(estimator.score(poly_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1000], # 1000 means no regularization\n",
    "        'class_weight': [None, 'balanced'],\n",
    "    }\n",
    "]\n",
    "\n",
    "clf_logs_4_1 = get_model(LogisticRegression, 'data/logistic_4.model_data', param_grid, 6, X=poly_train, Y=labels_train, default_param=dict(solver='lbfgs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'class_weight': None, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "params = clf_logs_4_1.best_params_\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.9742833333333333\n",
      "Accuracy on test set:\n",
      "0.9761\n"
     ]
    }
   ],
   "source": [
    "estimator = clf_logs_4_1.best_estimator_\n",
    "\n",
    "print('Accuracy on training set:')\n",
    "print(clf_logs_4_1.best_score_)\n",
    "\n",
    "print('Accuracy on test set:')\n",
    "print(estimator.score(poly_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried several svm for different parameters. Since SVM is so slow, I inserted only 10000 dataset for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train_sample, Y_train_sample = dataset_sampling(images_train, labels_train)\n",
    "\n",
    "print(X_train_sample.shape)\n",
    "print(Y_train_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 537)\n",
      "(10000, 537)\n"
     ]
    }
   ],
   "source": [
    "X_poly_train, X_poly_test = make_poly_features(X_train_sample, images_test)\n",
    "\n",
    "print(X_poly_train.shape)\n",
    "print(X_poly_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'C': [1, 10, 100, 1000],\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': ['auto', 'scale', 0.001, 0.01, 0.1]\n",
    "    },\n",
    "    {\n",
    "        'C': [1, 10, 100, 1000],\n",
    "        'kernel': ['poly'],\n",
    "        'gamma': ['auto', 'scale', 0.001, 0.01, 0.1],\n",
    "        'degree': [1, 2, 3]\n",
    "    }\n",
    "]\n",
    "\n",
    "clf_svm_4_1 = get_model(SVC, 'data/svm_4.model_data', param_grid=param_grid, cv=5, X=X_poly_train, Y=Y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "params = clf_svm_4_1.best_params_\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.9568\n",
      "Accuracy on test set:\n",
      "0.9568\n"
     ]
    }
   ],
   "source": [
    "estimator = clf_svm_4_1.best_estimator_\n",
    "\n",
    "print('Accuracy on training set:')\n",
    "print(clf_svm_4_1.best_score_)\n",
    "\n",
    "print('Accuracy on test set:')\n",
    "print(estimator.score(X_poly_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 179)\n",
      "(10000, 179)\n"
     ]
    }
   ],
   "source": [
    "X_poly_train, X_poly_test = make_poly_features(X_train_sample, images_test, poly_degree=1)\n",
    "\n",
    "print(X_poly_train.shape)\n",
    "print(X_poly_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'C': [1, 10, 100, 1000],\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': ['auto', 'scale', 0.001, 0.01, 0.1]\n",
    "    },\n",
    "    {\n",
    "        'C': [1, 10, 100, 1000],\n",
    "        'kernel': ['poly'],\n",
    "        'gamma': ['auto', 'scale', 0.001, 0.01, 0.1],\n",
    "        'degree': [3, 4, 5]\n",
    "    }\n",
    "]\n",
    "\n",
    "clf_svm_4_2 = get_model(SVC, 'data/svm_4_1.model_data', param_grid=param_grid, cv=5, X=X_poly_train, Y=Y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param = clf_svm_4_2.best_params_\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.9673\n",
      "Accuracy on test set:\n",
      "0.9662\n"
     ]
    }
   ],
   "source": [
    "estimator = clf_svm_4_2.best_estimator_\n",
    "\n",
    "print('Accuracy on training set:')\n",
    "print(clf_svm_4_2.best_score_)\n",
    "\n",
    "print('Accuracy on test set:')\n",
    "print(estimator.score(X_poly_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = make_poly_features(images_train, images_test, poly_degree=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JaeYoungLee\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator SVC from version 0.20.0 when using version 0.18.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "if pathlib.Path('data/svm_4_2.model_data').exists():\n",
    "    svm4 = joblib.load('data/svm_4_2.model_data')\n",
    "else:\n",
    "    svm4 = SVC(**param)\n",
    "    svm4.fit(X_train, labels_train)\n",
    "    joblib.dump(svm5, 'data/svm_4_2.model_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992166666666666\n",
      "0.9817\n"
     ]
    }
   ],
   "source": [
    "print(svm4.score(X_train, labels_train))\n",
    "print(svm4.score(X_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'C': [1, 10, 100, 1000],\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': ['auto', 'scale', 0.001, 0.01, 0.1]\n",
    "    },\n",
    "    {\n",
    "        'C': [1, 10, 100, 1000],\n",
    "        'kernel': ['poly'],\n",
    "        'gamma': ['auto', 'scale', 0.001, 0.01, 0.1],\n",
    "        'degree': [3, 4, 5]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "svm5 = get_model_without_gridsearch(SVC, 'data/svm_4_3.model_data')\n",
    "svm5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9924166666666666\n",
      "0.9823\n"
     ]
    }
   ],
   "source": [
    "print(svm5.score(X_train, labels_train))\n",
    "print(svm5.score(X_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = dict(C=svm5.C, gamma=svm5.gamma, kernel=svm5.kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9903666666666666\n",
      "0.9815\n"
     ]
    }
   ],
   "source": [
    "param['C'] = 7\n",
    "svm6 = get_model_without_gridsearch(SVC, 'data/svm_4_9.model_data', default_param=param, X=X_train, Y=labels_train)\n",
    "\n",
    "print(svm6.score(X_train, labels_train))\n",
    "print(svm6.score(X_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'C': [8.5, 10, 12.5],\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': ['scale']\n",
    "    }\n",
    "]\n",
    "\n",
    "clf_svm_4_5 = get_model(SVC, 'data/svm_4_5.model_data', param_grid=param_grid, cv=5, X=X_poly_train, Y=Y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 12.5, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.9659\n"
     ]
    }
   ],
   "source": [
    "param = clf_svm_4_5.best_params_\n",
    "print(param)\n",
    "\n",
    "print(clf_svm_4_5.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "param['C'] = 30\n",
    "\n",
    "svm_4_6 = get_model_without_gridsearch(SVC, 'data/svm_4_6.model_data', default_param=param, X=poly_train, Y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.9945333333333334\n",
      "Accuracy on test set: 0.9778\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training set:', svm_4_6.score(poly_train, labels_train))\n",
    "print('Accuracy on test set:', svm_4_6.score(poly_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.9920666666666667\n",
      "Accuracy on test set: 0.9777\n"
     ]
    }
   ],
   "source": [
    "param['C'] = 10\n",
    "\n",
    "svm_4_6 = get_model_without_gridsearch(SVC, 'data/svm_4_7.model_data', default_param=param, X=poly_train, Y=labels_train)\n",
    "\n",
    "print('Accuracy on training set:', svm_4_6.score(poly_train, labels_train))\n",
    "print('Accuracy on test set:', svm_4_6.score(poly_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.9815833333333334\n",
      "Accuracy on test set: 0.9701\n"
     ]
    }
   ],
   "source": [
    "param['C'] = 3\n",
    "\n",
    "svm_4_7 = get_model_without_gridsearch(SVC, 'data/svm_4_8.model_data', default_param=param, X=poly_train, Y=labels_train)\n",
    "\n",
    "print('Accuracy on training set:', svm_4_7.score(poly_train, labels_train))\n",
    "print('Accuracy on test set:', svm_4_7.score(poly_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron: Perceptron 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_train, poly_test = make_poly_features(images_train, images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95435\n",
      "0.9567\n"
     ]
    }
   ],
   "source": [
    "clf = get_model(Perceptron, 'data/perceptron_4.model_data')\n",
    "percp = clf.best_estimator_\n",
    "\n",
    "print(percp.score(poly_train, labels_train))\n",
    "print(percp.score(poly_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1e-05,\n",
       " 'class_weight': 'balanced',\n",
       " 'early_stopping': False,\n",
       " 'eta0': 1.0,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': None,\n",
       " 'n_iter': None,\n",
       " 'n_iter_no_change': 5,\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l1',\n",
       " 'random_state': 0,\n",
       " 'shuffle': True,\n",
       " 'tol': None,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percp.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: Logistic Regression 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_train, poly_test = make_poly_features(images_train, images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98665\n",
      "0.9761\n"
     ]
    }
   ],
   "source": [
    "clf = get_model(LogisticRegression, 'data/logistic_4.model_data')\n",
    "logs = clf.best_estimator_\n",
    "\n",
    "print(logs.score(poly_train, labels_train))\n",
    "print(logs.score(poly_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'warn',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine: SVM 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = make_poly_features(images_train, images_test, poly_degree=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9924166666666666\n",
      "0.9823\n"
     ]
    }
   ],
   "source": [
    "svc = get_model_without_gridsearch(SVC, 'data/svm_4_3.model_data')\n",
    "\n",
    "print(svc.score(X_train, labels_train))\n",
    "print(svc.score(X_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.0'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
